<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://gaolongsen.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://gaolongsen.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-05-28T03:41:13+00:00</updated><id>https://gaolongsen.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Receding Horizon Control (RHC) Algorithm</title><link href="https://gaolongsen.github.io/blog/2024/note1/" rel="alternate" type="text/html" title="Receding Horizon Control (RHC) Algorithm"/><published>2024-05-10T15:12:00+00:00</published><updated>2024-05-10T15:12:00+00:00</updated><id>https://gaolongsen.github.io/blog/2024/note1</id><content type="html" xml:base="https://gaolongsen.github.io/blog/2024/note1/"><![CDATA[<h2 id="receding-horizon-control-rhc-algorithm">Receding Horizon Control (RHC) Algorithm</h2> <p>Receding Horizon Control (RHC), also known as Model Predictive Control (MPC), is a popular control strategy in which the current control action is obtained by solving an open-loop optimal control problem at each time step. This approach involves predicting the future behavior of the system over a finite horizon and optimizing the control inputs accordingly.</p> <h3 id="key-components">Key Components</h3> <ol> <li><strong>Prediction Model</strong>: A mathematical model of the system dynamics used to predict future states based on current states and control inputs.</li> <li><strong>Prediction Horizon</strong>: A finite time window over which future states and control inputs are optimized.</li> <li><strong>Cost Function</strong>: An objective function that quantifies the performance of the system over the prediction horizon, typically involving terms for tracking error, control effort, and possibly state and input constraints.</li> <li><strong>Constraints</strong>: Physical or operational constraints on the states and control inputs, such as actuator limits or safety requirements.</li> </ol> <h3 id="algorithm-steps">Algorithm Steps</h3> <ol> <li> <p><strong>Measure or Estimate the Current State</strong>: Obtain the current state of the system ( x_k ).</p> </li> <li><strong>Solve the Optimization Problem</strong>: <ul> <li>Formulate an optimization problem over a finite prediction horizon ( N ). This involves predicting future states ( \(x_{k+1}, x_{k+2}, \ldots, x_{k+N}\)) and corresponding control inputs ( \(u_k, u_{k+1}, \ldots, u_{k+N-1}\) ).</li> <li> <p>The objective is to minimize a cost function ( J ) that typically takes the form:</p> <p>\(\sum_{i=k}^{k+N-1} \left( \| x_i - x_{\text{ref}} \|_Q^2 + \| u_i \|_R^2 \right)\) where ( x_{\text{ref}} ) is the reference state, and ( Q ) and ( R ) are weighting matrices.</p> </li> <li> <p>Subject to the system dynamics:</p> <p>\(x_{i+1} = f(x_i, u_i)\) and any state and input constraints:</p> \[x_i \in \mathcal{X}, \quad u_i \in \mathcal{U}\] </li> </ul> </li> <li> <p><strong>Apply the First Control Input</strong>:</p> <ul> <li>Implement the first control input ( u_k^* ) obtained from the optimization problem.</li> </ul> </li> <li> <p><strong>Recede the Horizon</strong>:</p> <ul> <li>Move the time index forward by one step, i.e., ( k \to k+1 ).</li> <li>Repeat the process from step 1 with updated state information.</li> </ul> </li> </ol> <h3 id="benefits">Benefits</h3> <ul> <li><strong>Optimal Performance</strong>: By solving an optimization problem at each time step, RHC can achieve near-optimal control performance.</li> <li><strong>Explicit Handling of Constraints</strong>: Constraints on states and inputs can be directly incorporated into the optimization problem, ensuring that the control actions respect these constraints.</li> <li><strong>Adaptability</strong>: The approach can adapt to changes in the system dynamics or the environment, as it recalculates the control actions at each time step.</li> </ul> <h3 id="example">Example</h3> <p>Consider a simple linear system:</p> <p>\(x_{k+1} = A x_k + B u_k\) with state ( x ) and control input ( u ). The goal is to track a reference trajectory ( x_{\text{ref}} ).</p> <ol> <li><strong>Prediction Model</strong>: Use the system dynamics to predict future states.</li> <li> <p><strong>Cost Function</strong>: Minimize a cost function over a prediction horizon ( N ):</p> \[\sum_{i=k}^{k+N-1} \left( (x_i - x_{\text{ref}})^T Q (x_i - x_{\text{ref}}) + u_i^T R u_i \right)\] </li> <li><strong>Solve Optimization</strong>: Solve for \(u_k, \ldots, u_{k+N-1}\) subject to the constraints.</li> <li><strong>Apply Control</strong>: Implement the first control input ( \(u_k\) ).</li> <li><strong>Recede Horizon</strong>: Move to the next time step and repeat the process.</li> </ol> <h3 id="conclusion">Conclusion</h3> <p>Receding Horizon Control is a powerful control strategy that leverages optimization techniques to achieve optimal control performance while explicitly handling constraints. Its ability to adapt to changing conditions and ensure constraint satisfaction makes it suitable for a wide range of applications, including robotics, process control, and automotive systems.</p>]]></content><author><name></name></author><category term="sample-posts"/><category term="MPC"/><summary type="html"><![CDATA[Learning note for robust MPC]]></summary></entry></feed>