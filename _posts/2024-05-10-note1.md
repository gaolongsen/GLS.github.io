---
layout: post
title: Receding Horizon Control (RHC) Algorithm
date: 2024-05-10 11:12:00-0400
description: Learning note for robust MPC
tags: MPC
categories: sample-posts
related_posts: false
---



## Receding Horizon Control (RHC) Algorithm

Receding Horizon Control (RHC), also known as Model Predictive Control (MPC), is a popular control strategy in which the current control action is obtained by solving an open-loop optimal control problem at each time step. This approach involves predicting the future behavior of the system over a finite horizon and optimizing the control inputs accordingly.

### Key Components

1. **Prediction Model**: A mathematical model of the system dynamics used to predict future states based on current states and control inputs.
2. **Prediction Horizon**: A finite time window over which future states and control inputs are optimized.
3. **Cost Function**: An objective function that quantifies the performance of the system over the prediction horizon, typically involving terms for tracking error, control effort, and possibly state and input constraints.
4. **Constraints**: Physical or operational constraints on the states and control inputs, such as actuator limits or safety requirements.

### Algorithm Steps

1. **Measure or Estimate the Current State**: Obtain the current state of the system  $x_k$.

2. **Solve the Optimization Problem**:

   - Formulate an optimization problem over a finite prediction horizon $ N $. This involves predicting future states $x_{k+1}, x_{k+2}, \ldots, x_{k+N}$ and corresponding control inputs $u_k, u_{k+1}, \ldots, u_{k+N-1}$.

   - The objective is to minimize a cost function $ J $ that typically takes the form: 
     $$
     \sum_{i=k}^{k+N-1} \left( \| x_i - x_{\text{ref}} \|_Q^2 + \| u_i \|_R^2 \right)
     $$
     where  $x_{\text{ref}}$  is the reference state, and  $Q$ and  $R$ are weighting matrices.

   - Subject to the system dynamics: 

     $$
     x_{i+1} = f(x_i, u_i)
     $$
     and any state and input constraints: 

     $$
     x_i \in \mathcal{X}, \quad u_i \in \mathcal{U}
     $$

3. **Apply the First Control Input**:

   - Implement the first control input $u_k^*$ obtained from the optimization problem.

4. **Recede the Horizon**:

   - Move the time index forward by one step, i.e., ($k \to k+1$).
   - Repeat the process from step 1 with updated state information.

### Benefits

- **Optimal Performance**: By solving an optimization problem at each time step, RHC can achieve near-optimal control performance.
- **Explicit Handling of Constraints**: Constraints on states and inputs can be directly incorporated into the optimization problem, ensuring that the control actions respect these constraints.
- **Adaptability**: The approach can adapt to changes in the system dynamics or the environment, as it recalculates the control actions at each time step.

### Example

Consider a simple linear system:

$$
x_{k+1} = A x_k + B u_k
$$
with state $x$ and control input  $u$. The goal is to track a reference trajectory  $x_{\text{ref}}$.

1. **Prediction Model**: Use the system dynamics to predict future states.

2. **Cost Function**: Minimize a cost function over a prediction horizon $N$:


$$
   \sum_{i=k}^{k+N-1} \left( (x_i - x_{\text{ref}})^T Q (x_i - x_{\text{ref}}) + u_i^T R u_i \right)
$$

3. **Solve Optimization**: Solve for  $u_k, \ldots, u_{k+N-1}$   subject to the constraints.

4. **Apply Control**: Implement the first control input $u_k$.

5. **Recede Horizon**: Move to the next time step and repeat the process.

### Conclusion

Receding Horizon Control is a powerful control strategy that leverages optimization techniques to achieve optimal control performance while explicitly handling constraints. Its ability to adapt to changing conditions and ensure constraint satisfaction makes it suitable for various applications, including robotics, process control, and automotive systems.

----------------------------------------------------------------------------------------------------------------------------

### Set-Membership Estimation

Set-membership estimation is an approach used in control theory and system identification to estimate the state or parameters of a system when the measurements are known to belong to a certain set. Unlike traditional methods that rely on probabilistic models and noise assumptions, set-membership estimation works with bounded uncertainties and provides guaranteed bounds on the estimation errors.

### Key Concepts

1. **Uncertain Models**: Systems where the exact model parameters are unknown but bounded within certain sets.
2. **Bounding Sets**: Sets containing all possible uncertainties, disturbances, or noise values.
3. **Feasible Set**: The set of all parameter or state values that are consistent with the given measurements and their bounds.

### Mathematical Formulation

Consider a system described by:

$$
y(t) = f(x(t), u(t), \theta) + v(t)
$$

where:

- $y(t)$ is the output.
- $x(t)$ is the state vector.
- $u(t)$ is the input vector.
- $\theta$ is the parameter vector.
- $v(t)$ represents the measurement noise or disturbance, which is bounded.

In set-membership estimation, we assume that the noise $v(t)$ belongs to a known bounded set $V$, typically described as:

$$
v(t) \in V = \{ v \in \mathbb{R}^m \mid \| v \| \leq \delta \}
$$

where $ \delta $ is a known bound on the noise.

### Estimation Process

1. **Initial Feasible Set**: Start with an initial feasible set for the parameters or states, $ \Theta_0 $.
2. **Update Feasible Set**: For each new measurement $ y(t) $, update the feasible set by intersecting the current feasible set with the set of values consistent with the new measurement and its bound.
3. **Recursive Update**: Continue updating the feasible set as new measurements become available.

### Example

Suppose we have a simple linear system:

$$
y(t) = \theta u(t) + v(t)
$$
where $ \theta $ is an unknown parameter to be estimated, and $v(t)$ is the noise bounded by $ |v(t)| \leq \delta $.

1. **Initial Feasible Set**: Assume an initial bound for the parameter $\theta$:
   $$
   \Theta_0 = [\theta_{\min}, \theta_{\max}]
   $$

2. **Measurement Update**: For a given input $ u(t) $ and measurement $ y(t) $, the feasible set for $ \theta $ is:
   $$
   \Theta_t = \{ \theta \in \Theta_{t-1} \mid y(t) - \delta \leq \theta u(t) \leq y(t) + \delta \}
   $$
   
3. **Recursive Update**: For each new measurement, update the feasible set:
   $$
   \Theta_{t+1} = \Theta_t \cap \{ \theta \in \mathbb{R} \mid y(t+1) - \delta \leq \theta u(t+1) \leq y(t+1) + \delta \}
   $$

### Benefits

1. **Guaranteed Bounds**: Provides guaranteed bounds on the estimation error.
2. **Robustness**: Effective in scenarios with bounded but unknown disturbances or noise.
3. **Non-Probabilistic**: Does not require probabilistic assumptions about noise or disturbances.

### Applications

1. **Fault Detection and Isolation**: Identifying faults in systems where uncertainties are bounded.
2. **Robust Control**: Designing controllers that can handle bounded uncertainties.
3. **System Identification**: Estimating parameters of systems with bounded noise.

### Conclusion

Set-membership estimation is a robust technique for estimating the state or parameters of a system in the presence of bounded uncertainties. By working with sets and ensuring that all feasible solutions are considered, this approach provides guaranteed bounds on the estimation errors and is particularly useful in applications where probabilistic noise models are not appropriate.
