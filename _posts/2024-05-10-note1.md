---
layout: post
title: Robust MPC Learning Note
date: 2024-05-10 11:12:00-0400
description: Learning note for robust MPC
tags: MPC
categories: sample-posts
related_posts: false
---

-----

This learning note is based on the paper `"Lorenzen, Matthias, Mark Cannon, and Frank AllgÃ¶wer. "Robust MPC with recursive model update." *Automatica* 103 (2019): 461-471."`

---



## Receding Horizon Control (RHC) Algorithm

Receding Horizon Control (RHC), also known as Model Predictive Control (MPC), is a popular control strategy in which the current control action is obtained by solving an open-loop optimal control problem at each time step. This approach involves predicting the future behavior of the system over a finite horizon and optimizing the control inputs accordingly.

### Key Components

1. **Prediction Model**: A mathematical model of the system dynamics used to predict future states based on current states and control inputs.
2. **Prediction Horizon**: A finite time window over which future states and control inputs are optimized.
3. **Cost Function**: An objective function that quantifies the performance of the system over the prediction horizon, typically involving terms for tracking error, control effort, and possibly state and input constraints.
4. **Constraints**: Physical or operational constraints on the states and control inputs, such as actuator limits or safety requirements.

### Algorithm Steps

1. **Measure or Estimate the Current State**: Obtain the current state of the system  $$x_k$$.

2. **Solve the Optimization Problem**:

   - Formulate an optimization problem over a finite prediction horizon $ N $. This involves predicting future states $$x_{k+1}, x_{k+2}, \ldots, x_{k+N}$$ and corresponding control inputs $$u_k, u_{k+1}, \ldots, u_{k+N-1}$$.

   - The objective is to minimize a cost function $$J$$ that typically takes the form: 
     $$
     \sum_{i=k}^{k+N-1} \left( \| x_i - x_{\text{ref}} \|_Q^2 + \| u_i \|_R^2 \right)
     $$
     where  $$x_{\text{ref}}$$  is the reference state, and  $$Q$$ and  $$R$$ are weighting matrices.

   - Subject to the system dynamics: 

     $$
     x_{i+1} = f(x_i, u_i)
     $$
     and any state and input constraints: 

     $$
     x_i \in \mathcal{X}, \quad u_i \in \mathcal{U}
     $$

3. **Apply the First Control Input**:

   - Implement the first control input $$u_k^*$$ obtained from the optimization problem.

4. **Recede the Horizon**:

   - Move the time index forward by one step, i.e., ($$k \to k+1$$).
   - Repeat the process from step 1 with updated state information.

### Benefits

- **Optimal Performance**: By solving an optimization problem at each time step, RHC can achieve near-optimal control performance.
- **Explicit Handling of Constraints**: Constraints on states and inputs can be directly incorporated into the optimization problem, ensuring that the control actions respect these constraints.
- **Adaptability**: The approach can adapt to changes in the system dynamics or the environment, as it recalculates the control actions at each time step.

### Example

Consider a simple linear system:


$$
x_{k+1} = A x_k + B u_k
$$


with state $$x$$ and control input  $$u$$. The goal is to track a reference trajectory  $$x_{\text{ref}}$$.

1. **Prediction Model**: Use the system dynamics to predict future states.

2. **Cost Function**: Minimize a cost function over a prediction horizon $$N$$:


$$
\sum_{i=k}^{k+N-1} \left( (x_i - x_{\text{ref}})^T Q (x_i - x_{\text{ref}}) + u_i^T R u_i \right)
$$

3. **Solve Optimization**: Solve for  $$u_k, \ldots, u_{k+N-1}$$   subject to the constraints.

4. **Apply Control**: Implement the first control input $$u_k$$.

5. **Recede Horizon**: Move to the next time step and repeat the process.

### Conclusion

Receding Horizon Control is a powerful control strategy that leverages optimization techniques to achieve optimal control performance while explicitly handling constraints. Its ability to adapt to changing conditions and ensure constraint satisfaction makes it suitable for various applications, including robotics, process control, and automotive systems.

----------------------------------------------------------------------------------------------------------------------------

### Set-Membership Estimation

Set-membership estimation is an approach used in control theory and system identification to estimate the state or parameters of a system when the measurements are known to belong to a certain set. Unlike traditional methods that rely on probabilistic models and noise assumptions, set-membership estimation works with bounded uncertainties and provides guaranteed bounds on the estimation errors.

### Key Concepts

1. **Uncertain Models**: Systems where the exact model parameters are unknown but bounded within certain sets.
2. **Bounding Sets**: Sets containing all possible uncertainties, disturbances, or noise values.
3. **Feasible Set**: The set of all parameter or state values that are consistent with the given measurements and their bounds.

### Mathematical Formulation

Consider a system described by:

$$
y(t) = f(x(t), u(t), \theta) + v(t)
$$

where:

- $$y(t)$$ is the output.
- $$x(t)$$ is the state vector.
- $$u(t)$$ is the input vector.
- $$\theta$$ is the parameter vector.
- $$v(t)$$ represents the measurement noise or disturbance, which is bounded.

In set-membership estimation, we assume that the noise $v(t)$ belongs to a known bounded set $V$, typically described as:

$$
v(t) \in V = \{ v \in \mathbb{R}^m \mid \| v \| \leq \delta \}
$$

where $ \delta $ is a known bound on the noise.

### Estimation Process

1. **Initial Feasible Set**: Start with an initial feasible set for the parameters or states, $$\Theta_0$$.
2. **Update Feasible Set**: For each new measurement $$y(t)$$, update the feasible set by intersecting the current feasible set with the set of values consistent with the new measurement and its bound.
3. **Recursive Update**: Continue updating the feasible set as new measurements become available.

### Example

Suppose we have a simple linear system:


$$
y(t) = \theta u(t) + v(t)
$$


where $$\theta$$ is an unknown parameter to be estimated, and $$v(t)$$ is the noise bounded by $$|v(t)| \leq \delta$$.

1. **Initial Feasible Set**: Assume an initial bound for the parameter $$\theta$$:

   
   $$
   \Theta_0 = [\theta_{\min}, \theta_{\max}]
   $$

2. **Measurement Update**: For a given input $$u(t)$$ and measurement $$y(t)$$, the feasible set for $$\theta$$ is:

   
   $$
   \Theta_t = \{ \theta \in \Theta_{t-1} \mid y(t) - \delta \leq \theta u(t) \leq y(t) + \delta \}
   $$

3. **Recursive Update**: For each new measurement, update the feasible set:

   
   $$
   \Theta_{t+1} = \Theta_t \cap \{ \theta \in \mathbb{R} \mid y(t+1) - \delta \leq \theta u(t+1) \leq y(t+1) + \delta \}
   $$

### Benefits

1. **Guaranteed Bounds**: Provides guaranteed bounds on the estimation error.
2. **Robustness**: Effective in scenarios with bounded but unknown disturbances or noise.
3. **Non-Probabilistic**: Does not require probabilistic assumptions about noise or disturbances.

### Applications

1. **Fault Detection and Isolation**: Identifying faults in systems where uncertainties are bounded.
2. **Robust Control**: Designing controllers that can handle bounded uncertainties.
3. **System Identification**: Estimating parameters of systems with bounded noise.

### Conclusion

Set-membership estimation is a robust technique for estimating the state or parameters of a system in the presence of bounded uncertainties. By working with sets and ensuring that all feasible solutions are considered, this approach provides guaranteed bounds on the estimation errors and is particularly useful in applications where probabilistic noise models are not appropriate.



--------

For **Eq.(12)** to **Eq.(13)** explains the recursive update of a parameter estimate $$\hat{\theta}_k$$ in a set-membership estimation context. Let's break down each part in detail.

#### Predicted State and Prediction Error

1. **Predicted State**:

   $$
   \hat{x}_{1|k} = A(\hat{\theta}_k)x_k + B(\hat{\theta}_k)u_k
   $$
   
   
   - This represents the predicted state at the next time step $$k+1$$ given the current parameter estimate $$\hat{\theta}_k$$.
   - $$A(\hat{\theta}_k) $$ and $$B(\hat{\theta}_k)$$ are matrices dependent on the parameter estimate $$\hat{\theta}_k$$.
   - $$x_k $$ is the current state, and $$u_k $$ is the current control input.
   
2. **Prediction Error**:

   $$
   \tilde{x}_{1|k} = A(\theta^*)x_k + B(\theta^*)u_k - \hat{x}_{1|k}
   $$
   
   
   - $$\tilde{x}_{1|k}$$ is the error between the true next state (using the true parameter $$\theta^*$$) and the predicted state (using the estimated parameter $$\hat{\theta}_k$$).
   - $$\theta^*$$ is the true parameter vector.

#### Parameter Update Rule

3. **Update Rule**:

   
   $$
   \hat{\theta}_k = \hat{\theta}_{k-1} + \mu D(x_{k-1}, u_{k-1})^\top (x_k - \hat{x}_{1|k-1})
   $$
   

   - $$\hat{\theta}_k$$ is the updated parameter estimate at time $$k$$.
   - $$\hat{\theta}_{k-1}$$ is the parameter estimate from the previous time step ($$k-1$$).
   - $$\mu \in \mathbb{R}_{>0}$$ is a positive scalar gain for the parameter update.
   - $$D(x_{k-1}, u_{k-1})$$ is a matrix or function derived from the state $$x_{k-1}$$ and input $$u_{k-1}$$. It represents the sensitivity or derivative of the system dynamics with respect to the parameters.
   - $$x_k-\hat{x}_{1 \mid k-1}$$ is the prediction error at time $$k$$ using the estimate from time $$k-1$$.

4. **Projection onto the Parameter Set**:

   $$
   \hat{\theta}_k = \Pi_{\Theta}(\tilde{\theta}_k)
   $$
   
   
   - $$\tilde{\theta}_k$$ is the intermediate parameter estimate after applying the update rule.
   - $$\Pi_{\Theta}(\tilde{\theta}_k)$$ denotes the projection of $$\tilde{\theta}_k$$ onto the parameter set $$\Theta$$.
   - The projection ensures that the parameter estimate $$\hat{\theta}_k$$ remains within the feasible set $$\Theta$$, which is defined as:
     
     $$
     \Pi_{\Theta}(\tilde{\theta}) = \arg\min_{\theta \in \Theta} \|\theta - \tilde{\theta}\|
     $$
     
     This represents the point in $$\Theta$$ closest to $$\tilde{\theta}$$ in the Euclidean sense.

### Detailed Steps

1. **Prediction**:
   - Calculate the predicted state ![](https://latex.codecogs.com/svg.latex?%5C%5C%20%5Chat%7Bx%7D_%7B1%7Ck%7D) using the current parameter estimate ![](https://latex.codecogs.com/svg.image?\hat{\theta}_k&space;).
   - Compute the prediction error ![](https://latex.codecogs.com/svg.image?\tilde{x}_{1\mid&space;k}) based on the true parameter ![](https://latex.codecogs.com/svg.image?\theta^*).

2. **Update**:
   - Update the parameter estimate ![](https://latex.codecogs.com/svg.image?\hat{\theta}_{k-1}) using the prediction error and the sensitivity matrix ![](https://latex.codecogs.com/svg.image?D(x_{k-1},u_{k-1})).
   - The term ![](https://latex.codecogs.com/svg.image?\mu&space;D\left(x_{k-1},u_{k-1}\right)^{\top}\left(x_k-\hat{x}_{1\mid&space;k-1}\right)) adjusts the parameter estimate in the direction that reduces the prediction error.

3. **Projection**:
   - Ensure the updated parameter estimate $$\hat{\theta}_k$$ stays within the feasible set $$\Theta$$ by projecting $$\tilde{\theta}_k$$ onto $$\Theta$$.

### Conditions

The update gain $$\mu$$ must satisfy the condition:


$$
\frac{1}{\mu} > \sup_{(x,u) \in \mathcal{Z}} \|D(x,u)\|^2
$$


- This condition ensures that the update step does not diverge and remains stable.

- $$\mathcal{Z}$$ represents the set of all possible states and inputs.

- Mathematically, it can be rewritten as: 

  ![](https://latex.codecogs.com/svg.image?\mu<\frac{1}{\sup&space;_{(x,u)\in\mathcal{Z}}\|D(x,u)\|^2})

  This ensures that $$\mu$$ is small enough to provide a stable update rule.

### Summary

The given mathematical expressions describe a recursive parameter estimation algorithm that iteratively updates the parameter estimate $$\hat{\theta}_k$$ based on the prediction error while ensuring that the estimate remains within a feasible set $$\Theta$$. The key steps involve predicting the next state, computing the prediction error, updating the parameter estimate, and projecting it back onto the feasible set to maintain consistency with the prior knowledge or constraints. This approach is widely used in adaptive control and system identification to handle parameter uncertainties and ensure robust performance.
